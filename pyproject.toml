[tool.poetry]
name = "llama-kernel"
version = "0.1.0"
description = "Memory-efficient PyTorch kernel for Llama 3.2 inference"
authors = ["Your Name <your.email@example.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.9"
torch = "^2.1.0"
transformers = "^4.36.0"
accelerate = ">=0.26.0"
safetensors = "^0.4.0"
einops = "^0.7.0"
psutil = "^5.9.5"
matplotlib = "^3.7.2"
flash-attn = "^2.5.0"
ninja = "^1.11.1"

[tool.poetry.group.dev.dependencies]
black = "^23.11.0"
isort = "^5.12.0"
pytest = "^7.4.3"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api" 